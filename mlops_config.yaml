# OhanaAI MLOps Configuration
# Complete configuration for continuous GEDCOM processing and training pipeline

# API Server Configuration
api:
  host: "0.0.0.0"
  port: 8000
  debug: false
  cors_origins: ["*"]  # Configure for production
  
# Authentication
auth:
  secret_key: "change_this_in_production_ohana_ai_secret_key_12345"
  token_expire_hours: 24
  rate_limit:
    max_requests: 1000
    window_minutes: 60

# Database Configuration
database:
  path: "ohana_mlops.db"
  backup_interval_hours: 6
  cleanup_interval_days: 30

# Storage Configuration
storage:
  backend: "local"  # local, s3, gcs
  local:
    base_path: "storage"
  s3:
    bucket_name: "ohanaai-storage"
    region: "us-east-1"
    # aws_access_key_id: "set_via_env"
    # aws_secret_access_key: "set_via_env"
  gcs:
    bucket_name: "ohanaai-storage"
    # credentials_path: "path/to/service-account.json"

# Pipeline Configuration
pipeline:
  # Trigger settings
  min_files_for_training: 3
  auto_training_enabled: true
  training_schedule_hours: [2, 14]  # 2 AM and 2 PM
  
  # Processing settings
  max_concurrent_processing: 4
  max_graph_cache_size_gb: 5.0
  cache_ttl_days: 30
  upload_check_interval: 5.0
  
  # Training settings
  incremental_training: true
  min_improvement_threshold: 0.001
  max_training_time_hours: 4.0
  
  # Model versioning
  keep_model_versions: 10
  auto_deploy_threshold: 0.02

# Monitoring Configuration
monitoring:
  metrics_collection_interval: 30.0
  alert_check_interval: 60.0
  max_history_points: 2880  # 24 hours at 30s intervals
  
  # Alert Rules
  alerts:
    - name: "high_cpu_usage"
      metric: "cpu_percent"
      condition: "gt"
      threshold: 80.0
      duration_minutes: 5
      severity: "warning"
      enabled: true
    
    - name: "high_memory_usage"
      metric: "memory_percent"
      condition: "gt"
      threshold: 85.0
      duration_minutes: 3
      severity: "warning"
      enabled: true
    
    - name: "low_disk_space"
      metric: "disk_free_gb"
      condition: "lt"
      threshold: 5.0
      duration_minutes: 1
      severity: "error"
      enabled: true
    
    - name: "processing_queue_backup"
      metric: "processing_queue_size"
      condition: "gt"
      threshold: 50.0
      duration_minutes: 10
      severity: "warning"
      enabled: true

# Webhook Configuration
webhooks:
  enabled: true
  host: "0.0.0.0"
  port: 8080
  token: "change_this_webhook_token_in_production"
  
  # Notification URLs
  notifications:
    - url: "https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"
      events: ["training_complete", "training_failed", "system_error"]
    - url: "https://api.pushover.net/1/messages.json"
      events: ["critical_alert"]

# File Upload Configuration
uploads:
  directory: "uploads"
  max_file_size_mb: 100
  allowed_extensions: [".ged", ".gedcom"]
  virus_scan_enabled: false
  
  # Auto-processing
  auto_process: true
  stability_check_seconds: 2.0

# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/mlops.log"
  max_file_size_mb: 50
  backup_count: 5
  
  # Component-specific levels
  levels:
    "ohana_ai.mlops.pipeline": "INFO"
    "ohana_ai.mlops.database": "INFO"
    "ohana_ai.mlops.monitoring": "WARNING"
    "uvicorn": "WARNING"

# Model Training Configuration (inherits from main config.yaml)
training:
  # Override specific settings for MLOps
  early_stopping:
    patience: 10
    min_delta: 0.001
  
  # Data validation
  min_individuals: 50
  min_families: 20
  max_missing_data_percent: 30.0
  
  # Resource limits
  max_memory_gb: 8.0
  timeout_hours: 6.0

# Backup and Recovery
backup:
  enabled: true
  interval_hours: 12
  retention_days: 30
  
  # What to backup
  include:
    - "ohana_mlops.db"
    - "experiments/"
    - "storage/"
  
  # Backup destinations
  destinations:
    local: "backups/"
    # s3: "s3://ohanaai-backups/"

# Security Settings
security:
  encrypt_at_rest: false
  audit_log_enabled: true
  allowed_ips: []  # Empty means allow all
  
  # File validation
  scan_uploads: true
  max_upload_rate_per_ip: 10  # files per hour

# Performance Tuning
performance:
  # Database
  db_connection_pool_size: 10
  db_query_timeout: 30
  
  # Processing
  graph_batch_size: 32
  parallel_processing_workers: 4
  
  # Caching
  enable_graph_cache: true
  cache_compression: true
  
# Development Settings
development:
  debug_mode: false
  hot_reload: false
  mock_training: false  # Use mock training for development
  sample_data_enabled: false

# Production Settings
production:
  health_check_interval: 30
  graceful_shutdown_timeout: 30
  worker_restart_interval_hours: 24
  
  # Load balancing (for multiple instances)
  load_balancer:
    enabled: false
    strategy: "round_robin"
    health_check_path: "/health"

# Integration Settings
integrations:
  # MLflow (optional)
  mlflow:
    enabled: false
    tracking_uri: "http://localhost:5000"
    experiment_name: "ohanaai_genealogy"
  
  # Weights & Biases (optional)
  wandb:
    enabled: false
    project: "ohanaai"
    entity: "your-wandb-entity"
  
  # Custom webhooks
  custom_webhooks:
    training_complete: []
    model_deployed: []
    error_occurred: []